{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7e86d58-620a-4034-84ec-2b4e45d95d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1e355c-7097-4d6d-9a92-8fd412e2f05c",
   "metadata": {},
   "source": [
    "### 로컬에 저장된 모델을 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "873d192a-3001-4960-a245-2500bff614e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"google/gemma-2-2b-it\"\n",
    "model_path = f\"./HF_Models/{model_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b4cecd7-7909-4b78-958c-623dd12300f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b3772ceb0804716bcb0d1f3ad88cde5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_id, cache_dir=model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id,cache_dir=model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18fbca9-47b9-4145-a84d-8370f96d5396",
   "metadata": {},
   "source": [
    "### 모델에 전달할 프롬프트를 임베딩합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2025ebb1-4123-487d-a5bc-758004972c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"너는 친절한 AI 지식 서비스 엔진이야. \n",
    "다음 질문에 답변해줘. 답변만 말해줘:\n",
    "\n",
    "질문: 대한민국 1월 평균 오전 날씨는 몇도야?\n",
    "답변:\"\"\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6b9e82d-2841-4dd9-8fc4-f981c0d0502e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[     2, 239632, 236214, 149703, 240046, 236511,  16481,  34805, 238186,\n",
      "         206586, 209560, 237589, 235832, 238305, 235265, 235248,    108, 236039,\n",
      "         238036, 160587, 237465, 236179, 235248, 241305, 239042, 237138, 244669,\n",
      "         235265, 235248, 241305, 239042, 237598,  72163, 237138, 244669, 235292,\n",
      "            109, 239574, 237465, 235292, 216101, 237522, 235248, 235274, 237699,\n",
      "         119339, 242018,  44245, 237045, 128856, 241215, 236214, 235248, 242394,\n",
      "         236840, 238305, 235336,    108, 241305, 239042, 235292]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1843929d-62ef-4f62-90e3-306253bc2d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_len = inputs.input_ids.shape[1]+ 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f5231f-95b1-4a53-a8c0-3864298e80d0",
   "metadata": {},
   "source": [
    "### 임베딩된 프롬프트를 모델에 전달하여 답변을 얻습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6be37d81-d2a8-4a6d-9a78-32ee110dc3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The 'batch_size' attribute of HybridCache is deprecated and will be removed in v4.49. Use the more precisely named 'self.max_batch_size' attribute instead.\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(\n",
    "    inputs.input_ids,\n",
    "    do_sample=True,\n",
    "    min_length=10,\n",
    "    max_length=input_len+10,\n",
    "    repetition_penalty=1.5,\n",
    "    no_repeat_ngram_size=3,\n",
    "    temperature=1,\n",
    "    top_k=50,\n",
    "    top_p=0.92\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16645c5f-b2d3-44e5-a812-16413e613687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "너는 친절한 AI 지식 서비스 엔진이야. \n",
      "다음 질문에 답변해줘. 답변만 말해줘:\n",
      "\n",
      "질문: 대한민국 1월 평균 오전 날씨는 몇도야?\n",
      "답변:  **2°C ~ 5 ° C **\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90708993-8582-49d8-b76f-4f8de03b6063",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
